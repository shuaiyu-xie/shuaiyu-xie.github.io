<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"shuaiyuxie.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="题目：ElasticRec: A Microservice-based Model Serving Architecture Enabling Elastic Resource Scaling for Recommendation Models 来源：ISCA 2024 作者：韩国科学技术院  摘要 推荐系统（RecSys）广泛应用在许多线上服务中，为增加RecSys的推理时的吞吐">
<meta property="og:type" content="article">
<meta property="og:title" content="[ISCA 2024]  ElasticRec: A Microservice-based Model Serving Architecture Enabling Elastic Resource Scaling for Recommendation Models">
<meta property="og:url" content="https://shuaiyuxie.github.io/2024/11/27/ElasticRec/index.html">
<meta property="og:site_name" content="衍射的博客">
<meta property="og:description" content="题目：ElasticRec: A Microservice-based Model Serving Architecture Enabling Elastic Resource Scaling for Recommendation Models 来源：ISCA 2024 作者：韩国科学技术院  摘要 推荐系统（RecSys）广泛应用在许多线上服务中，为增加RecSys的推理时的吞吐">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/DLRM.jpg">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/DLRM_inference.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/%E5%BC%82%E6%9E%84%E8%B5%84%E6%BA%90%E9%9C%80%E6%B1%82.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/%E5%90%9E%E5%90%90%E9%87%8F.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/%E5%9B%BE5.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/%E5%80%BE%E6%96%9C%E8%AE%BF%E9%97%AE.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/%E6%9E%B6%E6%9E%84.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/sort.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/cost_estimate.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/QPS_predict.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/DP.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/DP_algo.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/remap.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/config.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/Microbenchmarks.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/cpu-only-exp.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/CPU-GPU-exp.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/dynamic-workload.png">
<meta property="og:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/compare-GPU-cache.png">
<meta property="article:published_time" content="2024-11-27T02:29:27.000Z">
<meta property="article:modified_time" content="2025-05-07T03:06:04.723Z">
<meta property="article:author" content="谢帅宇">
<meta property="article:tag" content="微服务">
<meta property="article:tag" content="推荐系统">
<meta property="article:tag" content="资源管理">
<meta property="article:tag" content="面向AI的微服务">
<meta property="article:tag" content="ISCA">
<meta property="article:tag" content="2024">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shuaiyuxie.github.io/imgs/ElasticRec/DLRM.jpg">

<link rel="canonical" href="https://shuaiyuxie.github.io/2024/11/27/ElasticRec/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>[ISCA 2024]  ElasticRec: A Microservice-based Model Serving Architecture Enabling Elastic Resource Scaling for Recommendation Models | 衍射的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="衍射的博客" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">衍射的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录学习中的点点滴滴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-github">

    <a href="https://github.com/theoryXie" rel="noopener" target="_blank"><i class="fa fa-folder fa-fw"></i>github</a>

  </li>
        <li class="menu-item menu-item-homepage">

    <a href="https://theoryxie.github.io/" rel="noopener" target="_blank"><i class="fa fa-user fa-fw"></i>homepage</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/theoryXie" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shuaiyuxie.github.io/2024/11/27/ElasticRec/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.png">
      <meta itemprop="name" content="谢帅宇">
      <meta itemprop="description" content="我正在攻读武汉大学的博士学位，关注微服务领域的弹性伸缩、故障诊断以及数据管理等方面的工作">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="衍射的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [ISCA 2024]  ElasticRec: A Microservice-based Model Serving Architecture Enabling Elastic Resource Scaling for Recommendation Models
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-11-27 10:29:27" itemprop="dateCreated datePublished" datetime="2024-11-27T10:29:27+08:00">2024-11-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-07 11:06:04" itemprop="dateModified" datetime="2025-05-07T11:06:04+08:00">2025-05-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%96%87%E7%8C%AE%E7%B2%BE%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">文献精读</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>12 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>题目：ElasticRec: A Microservice-based Model Serving Architecture
Enabling Elastic Resource Scaling for Recommendation Models</p>
<p>来源：ISCA 2024</p>
<p>作者：韩国科学技术院</p>
</blockquote>
<h2 id="摘要">摘要</h2>
<p>推荐系统（<code>RecSys</code>）广泛应用在许多线上服务中，为增加<code>RecSys</code>的推理时的吞吐量，数据中心通常对<code>RecSys</code>进行模型级别（model-wise）的资源管理。然而，<code>RecSys</code>中不同模块有着异构的资源需求，比如：</p>
<ul>
<li><code>RecSys</code>中<code>MLP</code>模块 对于计算资源的需求高</li>
<li><code>RecSys</code>中<code>Embedding Table</code>模块对于内存资源的需求高</li>
</ul>
<p>如果将<code>RecSys</code>模型看作一个整体进行服务部署、资源分配等操作，势必会造成大量的资源浪费；但对<code>RecSys</code>模型中的每一层进行资源管理又是非常具有挑战性的（这里类似于单体应用和微服务应用的关系）。因此，作者提出了<code>ElasticRec</code>，一种基于微服务架构的推荐系统细粒度资源分配方法，目标是减少<strong>部署时的内存消耗</strong>，提升<code>RecSys</code>的吞吐量。</p>
<h2 id="背景">背景</h2>
<p>文章背景主要介绍了深度推荐模型的结构，以及深度推荐模型如何集成到Kubernetes集群中，为用户提供线上推理服务。</p>
<h3 id="深度推荐模型dlrm">深度推荐模型（DLRM）</h3>
<center>
<img src="/imgs/ElasticRec/DLRM.jpg" width='500'/>
</center>
<p>如图所示，深度推荐模型（<code>DLRM</code>）包含3个主要组件：</p>
<ul>
<li><code>Bottom MLP</code>
<ul>
<li>输入：dense input（比如 用户年龄）</li>
<li>输出：dense output（高维特征）</li>
<li>类型：<strong>计算敏感型</strong></li>
</ul></li>
<li><code>Embedding Table</code>
<ul>
<li>输入：多个 sparse input（比如 商品ID）</li>
<li>输出：dense output（高维特征）</li>
<li>类型：<strong>内存敏感型</strong></li>
<li>作用：根据稀疏输入得到<code>Embedding Table</code>中的高维特征。一般来说，一次查询中所有的sparse
input得到的dense
output会执行<code>pool</code>操作进行池化，得到单个dense output</li>
</ul></li>
<li><code>Top MLP</code>
<ul>
<li>输入：<code>Bottom MLP</code>的输出 拼接
<code>Embedding Table</code>的输出</li>
<li>输出：给商品打分</li>
</ul></li>
</ul>
<blockquote>
<p>在生产环境中，由于商品（item）的种类非常多，比如Amazon有数亿的商品种类。<code>Embedding Table</code>为每个商品种类都维护了一个特征，导致<code>Embedding Table</code>的大小可以达到<strong>几十GB</strong>，相比于<code>Bottom MLP</code>，有几点需要关注：</p>
<ol type="1">
<li><code>Embedding Table</code>对于计算不敏感，即<code>pool</code>操作并不需要太多计算资源；相反，对于内存带宽限制极为敏感，特别是有非常多的dense
output需要<code>pool</code>时</li>
<li>在<code>DLRM</code>中，<code>Embedding Table</code>通常有<u>多个</u>，对内存的压力是极大的</li>
</ol>
</blockquote>
<h3 id="模型服务架构model-serving-architectures">模型服务架构（Model
Serving Architectures）</h3>
<h4 id="模型容器化">模型容器化</h4>
<p>这篇文章关注的是<code>DLRM</code>的推理。在线上应用中，<code>DLRM</code>被打包成镜像，镜像中包含了模型参数以及常用的机器学习库，以容器的方式运行在Kubernetes集群中，如Fig.
2（a）所示。</p>
<center>
<img src="/imgs/ElasticRec/DLRM_inference.png" width='500'/>
</center>
<h4 id="模型的自动伸缩">模型的自动伸缩</h4>
<p><strong>Kubernetes</strong>是一个容器编排工具，它能管理容器的生命周期，对容器进行自动化调度、资源分配。</p>
<p><strong>吞吐量</strong>是一个衡量在线服务性能的指标，单位是QPS（query
per second），吞吐量越高，代表在线服务单位时间内处理请求的数量</p>
<p>对于<code>DLRM</code>而言，处理单个请求的时间基本可以看作变化很小的，那么为提高吞吐量，可以采用Kubernetes的水平pod伸缩（Horizontal
Pod Autoscaling，HPA）机制对<code>DLRM</code>进行副本复制，如Fig. 2 (b)
所示，增加<code>DLRM</code>的副本数可以提高系统的并行处理能力，从而增大吞吐量</p>
<p>然而，HPA 是一种 model-wise
的分配方案，它将整个<code>DLRM</code>模型进行复制，包括内存占用非常大的<code>Embedding Table</code>模块，<u>但实际上<code>Embedding Table</code>并不涉及复杂的计算，所以一般不是（不是绝对）吞吐量的瓶颈所在。</u>无脑进行HPA势必会造成大量内存浪费。</p>
<h4 id="模型的硬件约束">模型的硬件约束</h4>
<p>因为 大型 <code>DLRM</code> 的 <code>Embedding Table</code>
通常有几十GB，将 <code>Embedding Table</code>
全部放在高内存带宽的GPU中通常不太可行，所以会退而求其次的使用如下两种方式：①
CPU-only ② CPU-GPU。</p>
<ul>
<li><strong>CPU-only</strong>：<code>Bottom MLP</code> 和
<code>Embedding Table</code> 均运行在CPU</li>
<li><strong>CPU-GPU</strong>：<code>Bottom MLP</code> 运行在GPU，
<code>Embedding Table</code> 均运行在CPU</li>
</ul>
<p>可以看到， <code>Embedding Table</code>
都运行在CPU关联的内存上，如果能优化这一部分的内存使用，就可以提升<code>DLRM</code>的最大副本数量，从而提高系统的吞吐量。</p>
<h2 id="动机">动机</h2>
<p>文章的动机从两点出发，阐述为什么现有的资源分配方案会导致次优性能（sub-optimal
performance）：</p>
<ol type="1">
<li><code>RecSys</code>的不同模块具有异构资源需求</li>
<li><code>Embedding Table</code>不同部分的访问频率相差极大</li>
</ol>
<h3 id="异构资源需求">异构资源需求</h3>
<p>Fig. 3 (a)
展示了三个推荐模型（RM1，RM2，RM3）的不同模块<code>Bottom MLP</code> 和
<code>Embedding Table</code> 在 ①计算复杂度（FLOPS）和 ②内存大小
上的差别。可以看出：<u><code>Bottom MLP</code>在计算复杂度上远高于
<code>Embedding Table</code>，但是内存占用远远小于
<code>Embedding Table</code></u></p>
<p>Fig.3 (b)
展示了三个推荐模型的不同模块在两种硬件约束下的延时占比。原文虽然没有讨论，但可以推测，<u>在CPU-only架构下，推理的延时开销主要集中在<code>Bottom MLP</code>的计算；在CPU-GPU架构下，延时的开销在于将 <code>Embedding Table</code>
的数据从CPU传输到GPU</u></p>
<center>
<img src='/imgs/ElasticRec/异构资源需求.png' width='500'/>
</center>
<p>此外，文章还讨论了吞吐量的瓶颈问题，Fig.
4展示了作者的想法，实际上<code>Bottom MLP</code>
计算开销大，内存占用小，适合扩充副本来提升吞吐量；而
<code>Embedding Table</code>
本身吞吐量就很大，但是内存占用大，所以对于副本扩充应该谨慎。</p>
<center>
<img src='/imgs/ElasticRec/吞吐量.png' width='500'/>
</center>
<p>当然，作者还通过实验，验证了不同硬件约束下不同模块的吞吐量存在差异，来支撑上述想法：</p>
<center>
<img src='/imgs/ElasticRec/图5.png' width='500'/>
</center>
<blockquote>
<p><font color='blue'>综上所述，文章说明<code>RecSys</code>中不同模块的<strong>异构资源需求</strong>，以及<strong>吞吐量的差异</strong>。为后续对不同模块分别进行切分提供了实验依据</font></p>
</blockquote>
<h3 id="embedding-table-的倾斜访问模式">Embedding Table
的倾斜访问模式</h3>
<p>这一个实证分析较为简单，主要验证<code>Embedding Table</code>不同索引的访问频率的差异，如Fig.
6所示，在三个数据集中，大部分的访问集中在少数的索引（热点嵌入，hot
embeddings）</p>
<center>
<img src='/imgs/ElasticRec/倾斜访问.png' width='500'/>
</center>
<blockquote>
<p><font color='blue'>换句话说，将资源选择性地分配给 hot
embeddings，可以在提升吞吐量的同时，达到节省资源的目的</font></p>
</blockquote>
<h2 id="方法设计">方法设计</h2>
<p>Fig. 7展示了ElasticRec的系统架构，整体思路分为三个模块：</p>
<ol type="1">
<li>部署开销估计</li>
<li>基于动态规划（DP）的<code>Embedding Table</code>划分</li>
<li>推理时重索引</li>
</ol>
<center>
<img src='/imgs/ElasticRec/架构.png' width='500'/>
</center>
<h3 id="部署开销估计">部署开销估计</h3>
<p><strong>前置处理</strong>：将<code>Embedding Table</code>的index按照访问频率从大到小排序，hot
embeddings集中在最左侧</p>
<center>
<img src='/imgs/ElasticRec/sort.png' width='500'/>
</center>
<p>根据动机中提到的“<strong>将资源选择性地分配给 hot
embeddings，可以在提升吞吐量的同时，达到节省资源的目的</strong>”，文章将<code>Embedding Table</code>切分为shards，每个shard包含了<code>Embedding Table</code>的一部分index。<u>那么如何切分<code>Embedding Table</code>，以及如何评估切分策略的优劣呢？</u></p>
<p>文章首先定义了如何评估切分策略的优劣，切分策略的优劣由<font color='red'>固定吞吐量的前提下，所有shard的内存开销决定</font>。用最少的内存达到目标吞吐量，评估算法如下：</p>
<center>
<img src='/imgs/ElasticRec/cost_estimate.png' width='500'/>
</center>
<p>算法入口为<code>COST(k, j)</code>，表示范围为[k,j]的shard的内存消耗，这个内存消耗由两部分组成：</p>
<ul>
<li><code>REPLICAS(k,j)</code>：
计算特定吞吐量下，shard应该被分配的副本数量
<ol type="1">
<li>计算shard被访问的概率<code>probability</code>和被访问的向量数<code>ns</code>，<code>probability = CDF(j)- CDF(k)</code>，<code>ns = probability × nt</code></li>
<li>估计单个shard的副本在给定的访问向量数<code>ns</code>下能达到的<code>QPS</code>，<code>estimated QPS = QPS(ns)</code>，这里的<code>QPS()</code>是一个回归模型，可以线下测试得到</li>
<li>估计达到目标吞吐量<code>target_traffic</code>需要的副本数，<code>num_replicas = target_traffic/estimated_QPS</code></li>
</ol></li>
<li><code>CAPACITY(k,j)</code>：对于shard的每一个副本，计算存储embedding的内存开销
<ul>
<li>直接计算shard的副本大小：<code>(j − k +1)×(size_of_a_single_embedding_vector)</code></li>
</ul></li>
</ul>
<blockquote>
<p>这里需要特别注意回归模型<code>QPS()</code>，输入的参数除了需要访问的向量数<code>ns</code>外，还需要考虑向量本身的大小，如下图所示，QPS既与向量数有关，也与向量本身维度相关</p>
</blockquote>
<center>
<img src='/imgs/ElasticRec/QPS_predict.png' width='500'/>
</center>
<h3
id="基于dp的embedding-table分区算法">基于DP的<code>Embedding Table</code>分区算法</h3>
<p>在上一节中，当给定一个shard划分策略，我们可以评估每个shard在目标QPS下的内存开销，进而可以尝试找到给定QPS下最小内存开销的分区策略</p>
<p><u>这里文章有一个前提，即无论怎么划分，所有shard的目标QPS都是一样的，这样可以保证不存在多余的资源浪费</u></p>
<p>这个分区问题有两个操作：① 分多少shard
②每个shard的范围。假设我们用<span
class="math inline">\(Mem[num_{shards}][x]\)</span>表示<code>Embedding Table</code>在<span
class="math inline">\([0:x]\)</span>范围下，分区数量为<span
class="math inline">\(num_{shards}\)</span>的最小内存开销。那么这个问题具有两个明显的特性：<strong>最优子结构</strong>和<strong>重叠子问题</strong></p>
<ul>
<li><p><strong>最优子结构</strong>：<span
class="math inline">\(Mem[num_{shards}][x]\)</span>可以由子问题的最优解构造而来，假设最后一个shard的大小为<span
class="math inline">\(m\)</span>，那么可以简化表示为<span
class="math inline">\(Mem[num_{shards}][x] =
min(Mem[num_{shards}-1][x-m] + COST(m))\)</span>，比如下图中，<span
class="math inline">\(Mem[3][5]=min(Mem[2][5-m]+COST(m))=Mem[2][3]+COST(4,5)=4\)</span></p>
<center>
<p><img src='/imgs/ElasticRec/DP.png' width='500'/></p>
</center></li>
<li><p><strong>重叠子问题</strong>：求解过程中会反复遇到相同的子问题，需要将结果存储到表中，避免重复计算</p></li>
</ul>
<p>因此，自然而然可以想到用动态规划（DP）求解，文章给出的算法如下：</p>
<center>
<img src='/imgs/ElasticRec/DP_algo.png' width='500'/>
</center>
<p>最后根据最小内存开销回溯DP表可以得到分区策略</p>
<h3 id="推理时重索引">推理时重索引</h3>
<p>这个部分的重点在于分区后，如何根据原始<code>Embedding Table</code>的index
ID找到对应的shard中的某个embedding，以及确认index分别属于哪个input（为提高吞吐量，一个query包含了多个input）。</p>
<center>
<img src='/imgs/ElasticRec/remap.png' width='500'/>
</center>
<p>文章提出了两种索引：</p>
<ul>
<li><code>indices</code>：存储一次query要从<code>Embedding Table</code>中查找的具体ID。</li>
<li><code>offset</code>：指示每个input对应的的<code>indices</code>中的起始位置。</li>
</ul>
<p><strong>对于Fig.
11（a）未分区前</strong>，一个query（<code>indices</code>）包含了两个input，分别为红色的[1,
7]，灰色的[3,4,8]，<code>offset</code>表示第一个input要从<code>indices</code>第0个元素算起，第二个input从<code>indices</code>第1个元素算起，即input1为[1,7]，input2为[3,4,8]</p>
<p><strong>对于Fig.
11（b）分区后</strong>，首先计算中间的<code>indices</code>，具体为根据<code>indices</code>中的index计算应该被分到哪个分区（减去之前分区的大小），可以很容易把<code>indices</code>划分为shard
A 的[1,3,4]和shard B
的[7,8]，同时把<code>offset</code>进行划分（基于indices）</p>
<p><strong>对于Fig.
11（b）分区后，由于各shard索引重置了</strong>，所以需要在中间的<code>indices</code>和<code>offset</code>的基础上，进行重索引，具体为减去之前分区的大小，比如Fig.
11(b) 中 shard B的[7,8]减去shard
A的大小后，变成[1,2]。这样便可以直接从各shard中查找embedding了</p>
<h3 id="最终部署">最终部署</h3>
<p>因为Kubernetes的 horizontal pod autoscaling
提供了弹性伸缩时参考指标的接口，对于：</p>
<ul>
<li><code>Embedding Table</code>的shard，文章直接将每个shard可以承受的最大吞吐量作为参考指标，到达最大吞吐量则扩容</li>
<li><code>Bottom MLP</code>，则采用SLA的65%作为扩容的阈值</li>
</ul>
<p>（这里不是很明白为什么要采用不同的阈值指标，为什么不都用吞吐量？）</p>
<h2 id="实验部分">实验部分</h2>
<p>文章分别验证了 <code>ElasticRec</code> 在 <strong>CPU-only</strong>
以及 <strong>CPU-GPU</strong> 环境下的性能表现：</p>
<ul>
<li><strong>CPU-only</strong>：本地集群（1 master + 11 worknode）</li>
<li><strong>CPU-GPU</strong>：云集群（20 CPU-GPU nodes，GPU为 NVIDIA
Tesla T4，节点间有31Gbps的带宽）</li>
</ul>
<p><code>DLRM</code>模型的开发是基于facebook的dlrm<a
href="#dlrm"><sup>1</sup></a>。Kubernetes自动伸缩器采用的custom
metric来自prometheus。SLA设置为400ms。而对于验证的<code>DLRM</code>模型，作者选择了三个先进的推荐模型（RM1,
RM2,
RM3），并在RM1的基础上进行参数改造，设置了很多个microbenchmarks，参数变动和三个RM模型如下：</p>
<center>
<img src='/imgs/ElasticRec/config.png'/>
</center>
<p>其中 Locality 指标 <span class="math inline">\(P\)</span>
代表多少请求分布在前10%的热点向量，<span
class="math inline">\(P\)</span>越大，代表请求分布越集中在热点。</p>
<h3 id="microbenchmarks实验">Microbenchmarks实验</h3>
<p>文章一开始探讨了不同RM配置下的内存消耗：</p>
<center>
<img src='/imgs/ElasticRec/Microbenchmarks.png' width='500'/>
</center>
<ol type="1">
<li><strong>MLP size</strong>：随着MLP
size的扩大，计算复杂度提高，延时会逐渐违背SLA。<code>Model-wise</code>的方法会扩容整个模型，而<code>ElasticRec</code>只需要扩容内存开销极小的<code>Bottom MLP</code>，所以内存消耗差距很大</li>
<li><strong>Locality</strong>：访问越集中在热点，<code>ELasticRec</code>效果越好，因为只需要扩容热点那一部分</li>
<li><strong>Number of
tables</strong>：系统中可能不止一个<code>Embedding Table</code>，比如用户ID表和商品ID表，随着表数量的增多，<code>ELasticRec</code>对每个表都进行分片，降低扩容时的内存开销</li>
<li><strong>Number of
shards</strong>：分片数量并不是越多越好，因为每个shard会有最小内存消耗（程序运行必须的消耗），即算法1中的min_mem_alloc，所以当分片数量大于4后，效果没有那么明显了</li>
</ol>
<h3 id="不同-rm-在-cpu-only-环境下的性能">不同 RM 在 CPU-only
环境下的性能</h3>
<p>文章接下来在<strong>CPU-only</strong>环境下，比较了<code>ElasticRec</code>和<code>Model-wise</code>方法在三个推荐模型（RM1，RM2，RM3）的性能表现。以下实验都是在吞吐量为100QPS的下进行的</p>
<ol type="1">
<li>Fig. 13 展示了<strong>内存消耗</strong>的对比</li>
<li>Fig. 14
展示了<strong>内存利用率</strong>的对比，这里的<strong>内存利用率</strong>是作者自己定义的，表示<u>当前shard在前1000个请求中被访问的embedding的比例</u>，可以看出<code>Model-wise</code>只有一个shard（S1），并且<strong>内存利用率</strong>很低，对整个shard扩容显得很不值；<code>ElasticRec</code>有4个shard，前3个<strong>内存利用率</strong>很高（高频shard），最后一个非常低。</li>
<li>Fig. 15
展示了两种方法在吞吐量为100QPS所需要消耗的CPU服务器数量。这里我不太清楚是如何算出需要消耗的CPU服务器数量的（一般算的是虚拟CPU使用量？）</li>
</ol>
<center>
<img src='/imgs/ElasticRec/cpu-only-exp.png'/>
</center>
<h3 id="不同-rm-在-cpu-gpu-环境下的性能">不同 RM 在 CPU-GPU
环境下的性能</h3>
<p>在<strong>CPU-GPU</strong>环境下，<code>ElasticRec</code>将 MLP
模块设计为 GPU-centric 容器，将 Embedding Table 模块设计为只用 CPU
的容器；<code>Model-wise</code>
则将CPU和GPU都分配给一个容器。以下实验都是在吞吐量为100QPS的下进行的，实验效果如下</p>
<center>
<img src='/imgs/ElasticRec/CPU-GPU-exp.png'/>
</center>
<h3 id="动态输入流量实验">动态输入流量实验</h3>
<p>前几个实验都是在固定吞吐量（QPS=100）下进行的，这个实验动态调整流量大小，然后观察<code>ElasticRec</code>和<code>Model-wise</code>的吞吐量表现、资源消耗以及尾部延时。</p>
<p>流量大小先逐步增大，然后降到一个固定值</p>
<center>
<img src='/imgs/ElasticRec/dynamic-workload.png' width="500"/>
</center>
<p>可以发现，<code>ElasticRec</code>的吞吐量、内存消耗以及SLA违背都低于对比方法</p>
<h3 id="与-gpu-embedding-caches-的对比">与 GPU Embedding Caches
的对比</h3>
<p>GPU Embedding Caches
方法是之前的一个工作，原理是把<code>Embedding Table</code>的hot
embeddings存到GPU缓存中，能缓解CPU内存带宽压力（减少CPU与GPU的交互）</p>
<center>
<img src='/imgs/ElasticRec/compare-GPU-cache.png'/>
</center>
<p>文章对比了 <code>Model-wise</code>、<code>Model-wise (cache)</code>
和 <code>ElasticRec</code> 在200 QPS
的内存消耗，<code>ElasticRec</code>的内存消耗仍然是最低的</p>
<blockquote>
<p>这里我很好奇为什么不比较延时？<code>ElasticRec</code>延时应该比不过<code>Model-wise (cache)</code>，毕竟CPU和GPU交互需要时间。</p>
</blockquote>
<div>
<p><a name="dlrm"></a> [1]
<a>https://github.com/facebookresearch/dlrm</a></p>
</div>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>谢帅宇
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://shuaiyuxie.github.io/2024/11/27/ElasticRec/" title="[ISCA 2024]  ElasticRec: A Microservice-based Model Serving Architecture Enabling Elastic Resource Scaling for Recommendation Models">https://shuaiyuxie.github.io/2024/11/27/ElasticRec/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" rel="tag"># 微服务</a>
              <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" rel="tag"># 推荐系统</a>
              <a href="/tags/%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/" rel="tag"># 资源管理</a>
              <a href="/tags/%E9%9D%A2%E5%90%91AI%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1/" rel="tag"># 面向AI的微服务</a>
              <a href="/tags/ISCA/" rel="tag"># ISCA</a>
              <a href="/tags/2024/" rel="tag"># 2024</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/11/25/trie_tree/" rel="prev" title="前缀树（Prefix Tree）">
      <i class="fa fa-chevron-left"></i> 前缀树（Prefix Tree）
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/12/12/StatusScaler/" rel="next" title="[arxiv 2024] StatuScale: Status-aware and Elastic Scaling Strategy for Microservice Applications">
      [arxiv 2024] StatuScale: Status-aware and Elastic Scaling Strategy for Microservice Applications <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#摘要"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#背景"><span class="nav-number">2.</span> <span class="nav-text">背景</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#深度推荐模型dlrm"><span class="nav-number">2.1.</span> <span class="nav-text">深度推荐模型（DLRM）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型服务架构model-serving-architectures"><span class="nav-number">2.2.</span> <span class="nav-text">模型服务架构（Model
Serving Architectures）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型容器化"><span class="nav-number">2.2.1.</span> <span class="nav-text">模型容器化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型的自动伸缩"><span class="nav-number">2.2.2.</span> <span class="nav-text">模型的自动伸缩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型的硬件约束"><span class="nav-number">2.2.3.</span> <span class="nav-text">模型的硬件约束</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#动机"><span class="nav-number">3.</span> <span class="nav-text">动机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#异构资源需求"><span class="nav-number">3.1.</span> <span class="nav-text">异构资源需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#embedding-table-的倾斜访问模式"><span class="nav-number">3.2.</span> <span class="nav-text">Embedding Table
的倾斜访问模式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#方法设计"><span class="nav-number">4.</span> <span class="nav-text">方法设计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#部署开销估计"><span class="nav-number">4.1.</span> <span class="nav-text">部署开销估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于dp的embedding-table分区算法"><span class="nav-number">4.2.</span> <span class="nav-text">基于DP的Embedding Table分区算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#推理时重索引"><span class="nav-number">4.3.</span> <span class="nav-text">推理时重索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最终部署"><span class="nav-number">4.4.</span> <span class="nav-text">最终部署</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验部分"><span class="nav-number">5.</span> <span class="nav-text">实验部分</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#microbenchmarks实验"><span class="nav-number">5.1.</span> <span class="nav-text">Microbenchmarks实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不同-rm-在-cpu-only-环境下的性能"><span class="nav-number">5.2.</span> <span class="nav-text">不同 RM 在 CPU-only
环境下的性能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不同-rm-在-cpu-gpu-环境下的性能"><span class="nav-number">5.3.</span> <span class="nav-text">不同 RM 在 CPU-GPU
环境下的性能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#动态输入流量实验"><span class="nav-number">5.4.</span> <span class="nav-text">动态输入流量实验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#与-gpu-embedding-caches-的对比"><span class="nav-number">5.5.</span> <span class="nav-text">与 GPU Embedding Caches
的对比</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="谢帅宇"
      src="/images/head.png">
  <p class="site-author-name" itemprop="name">谢帅宇</p>
  <div class="site-description" itemprop="description">我正在攻读武汉大学的博士学位，关注微服务领域的弹性伸缩、故障诊断以及数据管理等方面的工作</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">谢帅宇</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">72k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:10</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
